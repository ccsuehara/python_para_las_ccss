{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oc6x7R2Y7XS"
      },
      "source": [
        "# Pandas (Parte 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckwwsei7Y7XT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pL-Cl7eLY7XU"
      },
      "source": [
        "## Visualizando los tipos de merge\n",
        "\n",
        "<img src=\"https://github.com/ccsuehara/python_para_las_ccss/blob/main/Clase%204/img/joinimages.png?raw=1\" width=\"500\">\n",
        "\n",
        "- Inner join: how = \"inner\"\n",
        "- Left outer join : how = \"left\"\n",
        "- Right outer join: how = \"right\"\n",
        "- Full outer join: how = \"outer\"\n",
        "\n",
        "Tomado de https://www.geeksforgeeks.org/python-pandas-merging-joining-and-concatenating/\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-B9Cn9rY7XV"
      },
      "outputs": [],
      "source": [
        "locacion_datos = \"https://otorongo.club/2021/json/ingresos/\"\n",
        "\n",
        "cong = pd.read_json(locacion_datos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpX9DlRjY7XV"
      },
      "outputs": [],
      "source": [
        "cong_1 = cong[['dni', 'total_ingreso']]\n",
        "\n",
        "cong_2 = cong[['dni', 'partido']]\n",
        "\n",
        "solo_vn = cong_2.loc[cong_2['partido'] == 'VICTORIA NACIONAL', :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLM0XdqBY7XV"
      },
      "source": [
        "Cómo es un outer merge?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIyuXBXDY7XV"
      },
      "outputs": [],
      "source": [
        "resultado_merge_vn = pd.merge(cong_1,\n",
        "                     solo_vn,\n",
        "                    left_on = 'dni',\n",
        "                    right_on = 'dni',\n",
        "                    how = 'outer')\n",
        "\n",
        "resultado_merge_vn\n",
        "#resultado_merge_vn.loc[resultado_merge_vn['partido'] != 'VICTORIA NACIONAL']\n",
        "#resultado_merge_vn.loc[resultado_merge_vn['partido'] == 'VICTORIA NACIONAL']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fZ2rUiCY7XV"
      },
      "source": [
        "Cómo es un left merge? Y un right merge?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APaoqil4Y7XW"
      },
      "outputs": [],
      "source": [
        "resultado_merge_vn = pd.merge(cong_1,\n",
        "                     solo_vn,\n",
        "                    left_on = 'dni',\n",
        "                    right_on = 'dni',\n",
        "                    how = 'left')\n",
        "#                    how = 'right')\n",
        "\n",
        "resultado_merge_vn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJHAdn6CY7XW"
      },
      "source": [
        "### Uniendo varias bases de datos horizontalmente (append)\n",
        "\n",
        "En pandas, este método se llama concat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6phtu-SY7XW"
      },
      "outputs": [],
      "source": [
        "df_partidos = {}\n",
        "for cat in cong['partido'].unique():\n",
        "    df = cong.loc[cong['partido'] == cat]\n",
        "    df_partidos[cat] = df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5ZsV1xeY7XW"
      },
      "outputs": [],
      "source": [
        "df_fp = df_partidos['FUERZA POPULAR']\n",
        "df_vn = df_partidos['VICTORIA NACIONAL']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc3wAZ_DY7XW"
      },
      "outputs": [],
      "source": [
        "df_append = pd.concat([df_vn,df_fp])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pX-XxiIY7XW"
      },
      "outputs": [],
      "source": [
        "#df_append"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9govmGnZY7XX"
      },
      "outputs": [],
      "source": [
        "df_append = pd.concat([df_partidos['FUERZA POPULAR'], df_partidos['VICTORIA NACIONAL']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZ_-XR8zY7XX"
      },
      "source": [
        "### Limpieza de datos (parte 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCqPtDGJY7XX"
      },
      "source": [
        "Eliminando columnas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2iDu6T3Y7XX"
      },
      "outputs": [],
      "source": [
        "#Creando (y eliminando) una columna que refleja un mal cálculo\n",
        "cong['calculo_mal_hecho'] = cong.eval('ingreso_publico + ingreso_privado')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flTfyKI7Y7XX"
      },
      "outputs": [],
      "source": [
        "cong.drop(columns = 'calculo_mal_hecho', inplace = True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynHBj6pjY7XX"
      },
      "source": [
        "Identificando (y eliminando) duplicados:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-crNwWDY7XX"
      },
      "outputs": [],
      "source": [
        "nueva_df = pd.concat([cong, cong])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64USvq2UY7XX"
      },
      "outputs": [],
      "source": [
        "nueva_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sos7j57pY7XY"
      },
      "outputs": [],
      "source": [
        "nueva_df.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8gJ8faRY7XY"
      },
      "outputs": [],
      "source": [
        "## Cuales son las dimensiones de nuestra dataframe si eliminamos las observaciones duplicadas\n",
        "nueva_df.drop_duplicates().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZt8U3dPY7XY"
      },
      "outputs": [],
      "source": [
        "nueva_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kjf14UqCY7XY"
      },
      "outputs": [],
      "source": [
        "sin_duplicados = nueva_df.drop_duplicates(subset='dni', keep = \"last\") ## métodos de keep:\n",
        "sin_duplicados.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ms0lO9t-Y7XY"
      },
      "outputs": [],
      "source": [
        "sin_duplicados_2 = nueva_df.drop_duplicates(subset=['dni','partido'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0Qk_gqLY7XY"
      },
      "source": [
        "### Manejando valores perdidos (missing)\n",
        "\n",
        "A continuación veremos cómo manejar valores perdidos (missing). Veremos 3 métodos en especial:\n",
        "- ` isna`\n",
        "- `dropna`\n",
        "- `fillna`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q6llBIoVY7XY"
      },
      "outputs": [],
      "source": [
        "cong_m = cong.copy(deep = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rY9I171Y7XY"
      },
      "outputs": [],
      "source": [
        "cong_m.replace({0:np.nan}, inplace = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzXzHJUFY7XZ"
      },
      "outputs": [],
      "source": [
        "cong_m.isna().head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3maKaNkKY7XZ"
      },
      "outputs": [],
      "source": [
        "cong_m.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzFrTDi6Y7XZ"
      },
      "outputs": [],
      "source": [
        "cong_m.isna().mean().round(4)*100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dp34RSQVY7XZ"
      },
      "outputs": [],
      "source": [
        "## Aquí vemos cuales observaciones se eliminarían\n",
        "cong_m.dropna().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxJ3H4B8Y7XZ"
      },
      "outputs": [],
      "source": [
        "cong_m.dropna(subset=['ingreso_publico', 'ingreso_privado']).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Arv99f9Y7XZ"
      },
      "outputs": [],
      "source": [
        "#cong_m.fillna('hola')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTHh5zyQY7XZ"
      },
      "outputs": [],
      "source": [
        "dict_fill = {'total_ingreso': 0, 'ingreso_publico': 'hola'}\n",
        "#cong_m.fillna(dict_fill)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "II9oC9dDY7XZ"
      },
      "outputs": [],
      "source": [
        "med_fill = cong_m.median(numeric_only=True)\n",
        "med_fill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clMKuvnKY7XZ"
      },
      "outputs": [],
      "source": [
        "med_fill = cong_m.median(numeric_only=True)\n",
        "\n",
        "cong_m.fillna(med_fill)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgSSk1xcY7Xk"
      },
      "source": [
        "### Haciendo un reshape de los datos (volver los datos de wide a long, y viceversa).\n",
        "\n",
        "<img src=\"https://github.com/ccsuehara/python_para_las_ccss/blob/main/Clase%204/img/wlong.png?raw=1\" width=\"500\">\n",
        "de: https://www.statology.org/long-vs-wide-data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXVVi1OSY7Xk"
      },
      "outputs": [],
      "source": [
        "categ_labels = ['cat_1', 'cat_2', 'cat_3', 'cat_4']\n",
        "categ_bins = [-1, 10000, 50000, 100000, 200000000]\n",
        "cong['cat_ingreso'] = pd.cut(cong['total_ingreso'],\n",
        "                              bins = categ_bins, labels = categ_labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0yNWE0MJY7Xk"
      },
      "outputs": [],
      "source": [
        "cong.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5AKGaPoY7Xk"
      },
      "outputs": [],
      "source": [
        "resumen = cong.pivot_table(index='partido', columns='cat_ingreso', values='total_ingreso', aggfunc='mean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpM4DnyvY7Xk"
      },
      "outputs": [],
      "source": [
        "resumen.columns = resumen.columns.astype(str) ### Tengo que convertir mis columnas, que eran \"Categorical indexes\" en strings (no siempre pasara esto, suele estar en string )\n",
        "#resumen['total'] =resumen.sum(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtTSKI5nY7Xl"
      },
      "outputs": [],
      "source": [
        "resumen = resumen.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUlfJW9SY7Xl"
      },
      "outputs": [],
      "source": [
        "resumen_melted = resumen.melt(id_vars = 'partido', value_vars = ['cat_1', 'cat_2', 'cat_3', 'cat_4'])\n",
        "resumen_melted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SLsJGUbY7Xl"
      },
      "source": [
        "## Apply\n",
        "A veces queremos aplicarle una función a cada observación de una variable. Esto no se puede directamente ya que pandas hace cálculos vectoriales. En estos casos usamos el apply.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77BDLNVbY7Xl"
      },
      "outputs": [],
      "source": [
        "## Usando las mismas categorías de ingresos de antes:\n",
        "def clasif_ing(ing):\n",
        "    if ing < 10000:\n",
        "        new_ing = 'cat_1'\n",
        "    elif ((ing >= 10000) & (ing < 50000)):\n",
        "          new_ing = 'cat_2'\n",
        "    else:\n",
        "          new_ing = 'cat_3'\n",
        "    return new_ing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jh7MjYxSY7Xl"
      },
      "outputs": [],
      "source": [
        "cong['nueva_cat'] = cong['total_ingreso'].apply(lambda x: clasif_ing(x))\n",
        "cong[['total_ingreso', 'nueva_cat']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHtTyUwXY7Xl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}